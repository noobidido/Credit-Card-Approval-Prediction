{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 >Credit Card Approval Prediction Using Sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Content<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Response-Variable\" data-toc-modified-id=\"Response-Variable-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Response Variable</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-Features\" data-toc-modified-id=\"Binary-Features-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Binary Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Gender</a></span></li><li><span><a href=\"#Having-a-car-or-not\" data-toc-modified-id=\"Having-a-car-or-not-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Having a car or not</a></span></li><li><span><a href=\"#Having-house-reality-or-not\" data-toc-modified-id=\"Having-house-reality-or-not-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Having house reality or not</a></span></li><li><span><a href=\"#Having-a-phone-or-not\" data-toc-modified-id=\"Having-a-phone-or-not-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>Having a phone or not</a></span></li><li><span><a href=\"#Having-an-email-or-not\" data-toc-modified-id=\"Having-an-email-or-not-1.2.1.5\"><span class=\"toc-item-num\">1.2.1.5&nbsp;&nbsp;</span>Having an email or not</a></span></li><li><span><a href=\"#Having-a-Work-Phone-or-not\" data-toc-modified-id=\"Having-a-Work-Phone-or-not-1.2.1.6\"><span class=\"toc-item-num\">1.2.1.6&nbsp;&nbsp;</span>Having a Work Phone or not</a></span></li></ul></li><li><span><a href=\"#Continuous-Variables\" data-toc-modified-id=\"Continuous-Variables-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Continuous Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Children-Numbers\" data-toc-modified-id=\"Children-Numbers-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Children Numbers</a></span></li><li><span><a href=\"#Annual-Income\" data-toc-modified-id=\"Annual-Income-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Annual Income</a></span></li><li><span><a href=\"#Age\" data-toc-modified-id=\"Age-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Age</a></span></li><li><span><a href=\"#Working-Years\" data-toc-modified-id=\"Working-Years-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>Working Years</a></span></li><li><span><a href=\"#Famliy-Size\" data-toc-modified-id=\"Famliy-Size-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>Famliy Size</a></span></li></ul></li><li><span><a href=\"#Categorical-Features\" data-toc-modified-id=\"Categorical-Features-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Categorical Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Income-Type\" data-toc-modified-id=\"Income-Type-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Income Type</a></span></li><li><span><a href=\"#Occupation-Type\" data-toc-modified-id=\"Occupation-Type-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>Occupation Type</a></span></li><li><span><a href=\"#House-Type\" data-toc-modified-id=\"House-Type-1.2.3.3\"><span class=\"toc-item-num\">1.2.3.3&nbsp;&nbsp;</span>House Type</a></span></li><li><span><a href=\"#Education\" data-toc-modified-id=\"Education-1.2.3.4\"><span class=\"toc-item-num\">1.2.3.4&nbsp;&nbsp;</span>Education</a></span></li><li><span><a href=\"#Marriage-Condition\" data-toc-modified-id=\"Marriage-Condition-1.2.3.5\"><span class=\"toc-item-num\">1.2.3.5&nbsp;&nbsp;</span>Marriage Condition</a></span></li></ul></li></ul></li><li><span><a href=\"#IV、WOE：Concept-and-Application\" data-toc-modified-id=\"IV、WOE：Concept-and-Application-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>IV、WOE：Concept and Application</a></span></li></ul></li><li><span><a href=\"#Algorithms\" data-toc-modified-id=\"Algorithms-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Xgboost\" data-toc-modified-id=\"Xgboost-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Xgboost</a></span></li><li><span><a href=\"#Keras-Neural-Networks\" data-toc-modified-id=\"Keras-Neural-Networks-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Keras Neural Networks</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:27:50.499913Z",
     "iopub.status.busy": "2025-01-03T14:27:50.499573Z",
     "iopub.status.idle": "2025-01-03T14:27:54.692329Z",
     "shell.execute_reply": "2025-01-03T14:27:54.691184Z",
     "shell.execute_reply.started": "2025-01-03T14:27:50.499853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:27:55.574742Z",
     "iopub.status.busy": "2025-01-03T14:27:55.574367Z",
     "iopub.status.idle": "2025-01-03T14:27:58.575153Z",
     "shell.execute_reply": "2025-01-03T14:27:58.573913Z",
     "shell.execute_reply.started": "2025-01-03T14:27:55.574670Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/application_record.csv\", encoding = 'utf-8') \n",
    "record = pd.read_csv(\"../input/credit_record.csv\", encoding = 'utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:27:59.971094Z",
     "iopub.status.busy": "2025-01-03T14:27:59.970737Z",
     "iopub.status.idle": "2025-01-03T14:27:59.975605Z",
     "shell.execute_reply": "2025-01-03T14:27:59.974549Z",
     "shell.execute_reply.started": "2025-01-03T14:27:59.971030Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:28:02.165238Z",
     "iopub.status.busy": "2025-01-03T14:28:02.164862Z",
     "iopub.status.idle": "2025-01-03T14:28:02.190736Z",
     "shell.execute_reply": "2025-01-03T14:28:02.189647Z",
     "shell.execute_reply.started": "2025-01-03T14:28:02.165160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001711</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5001712</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>5150487</td>\n",
       "      <td>-25</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>5150487</td>\n",
       "      <td>-26</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>5150487</td>\n",
       "      <td>-27</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>5150487</td>\n",
       "      <td>-28</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>5150487</td>\n",
       "      <td>-29</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  MONTHS_BALANCE STATUS\n",
       "0        5001711               0      X\n",
       "1        5001711              -1      0\n",
       "2        5001711              -2      0\n",
       "3        5001711              -3      0\n",
       "4        5001712               0      C\n",
       "...          ...             ...    ...\n",
       "1048570  5150487             -25      C\n",
       "1048571  5150487             -26      C\n",
       "1048572  5150487             -27      C\n",
       "1048573  5150487             -28      C\n",
       "1048574  5150487             -29      C\n",
       "\n",
       "[1048575 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:28:08.115872Z",
     "iopub.status.busy": "2025-01-03T14:28:08.115496Z",
     "iopub.status.idle": "2025-01-03T14:28:08.556614Z",
     "shell.execute_reply": "2025-01-03T14:28:08.555826Z",
     "shell.execute_reply.started": "2025-01-03T14:28:08.115798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0       5008804           M            Y               Y             0   \n",
      "1       5008805           M            Y               Y             0   \n",
      "2       5008806           M            Y               Y             0   \n",
      "3       5008808           F            N               Y             0   \n",
      "4       5008809           F            N               Y             0   \n",
      "...         ...         ...          ...             ...           ...   \n",
      "438552  6840104           M            N               Y             0   \n",
      "438553  6840222           F            N               N             0   \n",
      "438554  6841878           F            N               N             0   \n",
      "438555  6842765           F            N               Y             0   \n",
      "438556  6842885           F            N               Y             0   \n",
      "\n",
      "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0               427500.0               Working               Higher education   \n",
      "1               427500.0               Working               Higher education   \n",
      "2               112500.0               Working  Secondary / secondary special   \n",
      "3               270000.0  Commercial associate  Secondary / secondary special   \n",
      "4               270000.0  Commercial associate  Secondary / secondary special   \n",
      "...                  ...                   ...                            ...   \n",
      "438552          135000.0             Pensioner  Secondary / secondary special   \n",
      "438553          103500.0               Working  Secondary / secondary special   \n",
      "438554           54000.0  Commercial associate               Higher education   \n",
      "438555           72000.0             Pensioner  Secondary / secondary special   \n",
      "438556          121500.0               Working  Secondary / secondary special   \n",
      "\n",
      "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0             Civil marriage   Rented apartment      -12005          -4542   \n",
      "1             Civil marriage   Rented apartment      -12005          -4542   \n",
      "2                    Married  House / apartment      -21474          -1134   \n",
      "3       Single / not married  House / apartment      -19110          -3051   \n",
      "4       Single / not married  House / apartment      -19110          -3051   \n",
      "...                      ...                ...         ...            ...   \n",
      "438552             Separated  House / apartment      -22717         365243   \n",
      "438553  Single / not married  House / apartment      -15939          -3007   \n",
      "438554  Single / not married       With parents       -8169           -372   \n",
      "438555               Married  House / apartment      -21673         365243   \n",
      "438556               Married  House / apartment      -18858          -1201   \n",
      "\n",
      "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0                1                1           0           0             NaN   \n",
      "1                1                1           0           0             NaN   \n",
      "2                1                0           0           0  Security staff   \n",
      "3                1                0           1           1     Sales staff   \n",
      "4                1                0           1           1     Sales staff   \n",
      "...            ...              ...         ...         ...             ...   \n",
      "438552           1                0           0           0             NaN   \n",
      "438553           1                0           0           0        Laborers   \n",
      "438554           1                1           0           0     Sales staff   \n",
      "438555           1                0           0           0             NaN   \n",
      "438556           1                0           1           0     Sales staff   \n",
      "\n",
      "        CNT_FAM_MEMBERS  begin_month  \n",
      "0                   2.0        -15.0  \n",
      "1                   2.0        -14.0  \n",
      "2                   2.0        -29.0  \n",
      "3                   1.0         -4.0  \n",
      "4                   1.0        -26.0  \n",
      "...                 ...          ...  \n",
      "438552              1.0          NaN  \n",
      "438553              1.0          NaN  \n",
      "438554              1.0          NaN  \n",
      "438555              2.0          NaN  \n",
      "438556              2.0          NaN  \n",
      "\n",
      "[438557 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# find all users' account open month.\n",
    "begin_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "# print(begin_month)\n",
    "begin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "new_data=pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, users in risk should be in 3%, thus I choose users who overdue for more than 60 days as target risk users. Those samples are marked as '1', else are '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:32:21.133914Z",
     "iopub.status.busy": "2025-01-03T14:32:21.133509Z",
     "iopub.status.idle": "2025-01-03T14:32:21.301126Z",
     "shell.execute_reply": "2025-01-03T14:32:21.299579Z",
     "shell.execute_reply.started": "2025-01-03T14:32:21.133847Z"
    }
   },
   "outputs": [],
   "source": [
    "record['dep_value'] = None  # Initialize the column\n",
    "record.loc[record['STATUS'].isin(['2', '3', '4', '5']), 'dep_value'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T19:30:05.989956Z",
     "iopub.status.busy": "2025-01-02T19:30:05.989615Z",
     "iopub.status.idle": "2025-01-02T19:30:06.291565Z",
     "shell.execute_reply": "2025-01-02T19:30:06.290278Z",
     "shell.execute_reply.started": "2025-01-02T19:30:05.989906Z"
    }
   },
   "outputs": [],
   "source": [
    "cpunt=record.groupby('ID').count()\n",
    "cpunt['dep_value'][cpunt['dep_value'] > 0]='Yes' \n",
    "cpunt['dep_value'][cpunt['dep_value'] == 0]='No' \n",
    "cpunt = cpunt[['dep_value']]\n",
    "new_data=pd.merge(new_data,cpunt,how='inner',on='ID')\n",
    "new_data['target']=new_data['dep_value']\n",
    "new_data.loc[new_data['target']=='Yes','target']=1\n",
    "new_data.loc[new_data['target']=='No','target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T19:30:10.817732Z",
     "iopub.status.busy": "2025-01-02T19:30:10.817427Z",
     "iopub.status.idle": "2025-01-02T19:30:10.863716Z",
     "shell.execute_reply": "2025-01-02T19:30:10.862534Z",
     "shell.execute_reply.started": "2025-01-02T19:30:10.817683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     45318\n",
      "Yes      667\n",
      "Name: dep_value, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     0.985495\n",
       "Yes    0.014505\n",
       "Name: dep_value, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cpunt['dep_value'].value_counts())\n",
    "cpunt['dep_value'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ rename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns={'CODE_GENDER':'Gender','FLAG_OWN_CAR':'Car','FLAG_OWN_REALTY':'Reality',\n",
    "                         'CNT_CHILDREN':'ChldNo','AMT_INCOME_TOTAL':'inc',\n",
    "                         'NAME_EDUCATION_TYPE':'edutp','NAME_FAMILY_STATUS':'famtp',\n",
    "                        'NAME_HOUSING_TYPE':'houtp','FLAG_EMAIL':'email',\n",
    "                         'NAME_INCOME_TYPE':'inctp','FLAG_WORK_PHONE':'wkphone',\n",
    "                         'FLAG_PHONE':'phone','CNT_FAM_MEMBERS':'famsize',\n",
    "                        'OCCUPATION_TYPE':'occyp'\n",
    "                        },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna()\n",
    "new_data = new_data.mask(new_data == 'NULL').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=pd.DataFrame(new_data.columns,columns=['variable'])\n",
    "ivtable['IV']=None\n",
    "namelist = ['FLAG_MOBIL','begin_month','dep_value','target','ID']\n",
    "\n",
    "for i in namelist:\n",
    "    ivtable.drop(ivtable[ivtable['variable'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define `calc_iv` function to [calculate](https://www.kaggle.com/puremath86/iv-woe-starter-for-python) Information Value and WOE Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    print('This variable\\'s IV is:',iv)\n",
    "    print(df[feature].value_counts())\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummy(df, feature,rank=0):\n",
    "    pos = pd.get_dummies(df[feature], prefix=feature)\n",
    "    mode = df[feature].value_counts().index[rank]\n",
    "    biggest = feature + '_' + str(mode)\n",
    "    pos.drop([biggest],axis=1,inplace=True)\n",
    "    df.drop([feature],axis=1,inplace=True)\n",
    "    df=df.join(pos)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(df, col, binsnum, labels, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = 'gp' + '_' + col\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Gender'] = new_data['Gender'].replace(['F','M'],[0,1])\n",
    "print(new_data['Gender'].value_counts())\n",
    "iv, data = calc_iv(new_data,'Gender','target')\n",
    "ivtable.loc[ivtable['variable']=='Gender','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a car or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Car'] = new_data['Car'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Car'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Car','target')\n",
    "ivtable.loc[ivtable['variable']=='Car','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having house reality or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Reality'] = new_data['Reality'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Reality'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Reality','target')\n",
    "ivtable.loc[ivtable['variable']=='Reality','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['phone']=new_data['phone'].astype(str)\n",
    "print(new_data['phone'].value_counts(normalize=True,sort=False))\n",
    "new_data.drop(new_data[new_data['phone'] == 'nan' ].index, inplace=True)\n",
    "iv, data=calc_iv(new_data,'phone','target')\n",
    "ivtable.loc[ivtable['variable']=='phone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having an email or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['email'].value_counts(normalize=True,sort=False))\n",
    "new_data['email']=new_data['email'].astype(str)\n",
    "iv, data=calc_iv(new_data,'email','target')\n",
    "ivtable.loc[ivtable['variable']=='email','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a Work Phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['wkphone']=new_data['wkphone'].astype(str)\n",
    "iv, data = calc_iv(new_data,'wkphone','target')\n",
    "new_data.drop(new_data[new_data['wkphone'] == 'nan' ].index, inplace=True)\n",
    "ivtable.loc[ivtable['variable']=='wkphone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables\n",
    "\n",
    "#### Children Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['ChldNo'] >= 2,'ChldNo']='2More'\n",
    "print(new_data['ChldNo'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'ChldNo','target')\n",
    "ivtable.loc[ivtable['variable']=='ChldNo','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'ChldNo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual Income\n",
    "bins the data based on sample quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['inc']=new_data['inc'].astype(object)\n",
    "new_data['inc'] = new_data['inc']/10000 \n",
    "print(new_data['inc'].value_counts(bins=10,sort=False))\n",
    "new_data['inc'].plot(kind='hist',bins=50,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'inc', 3, [\"low\",\"medium\", \"high\"], qcut = True)\n",
    "iv, data = calc_iv(new_data,'gp_inc','target')\n",
    "ivtable.loc[ivtable['variable']=='inc','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_inc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "Bucketing Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Age']=-(new_data['DAYS_BIRTH'])//365\t\n",
    "print(new_data['Age'].value_counts(bins=10,normalize=True,sort=False))\n",
    "new_data['Age'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'Age',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data = calc_iv(new_data,'gp_Age','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','IV'] = iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working Years\n",
    "+ Equal-length Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['worktm']=-(new_data['DAYS_EMPLOYED'])//365\t\n",
    "new_data[new_data['worktm']<0] = np.nan # replace by na\n",
    "new_data['DAYS_EMPLOYED']\n",
    "new_data['worktm'].fillna(new_data['worktm'].mean(),inplace=True) #replace na by mean\n",
    "new_data['worktm'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'worktm',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data=calc_iv(new_data,'gp_worktm','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_worktm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Famliy Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize']=new_data['famsize'].astype(int)\n",
    "new_data['famsizegp']=new_data['famsize']\n",
    "new_data['famsizegp']=new_data['famsizegp'].astype(object)\n",
    "new_data.loc[new_data['famsizegp']>=3,'famsizegp']='3more'\n",
    "iv, data=calc_iv(new_data,'famsizegp','target')\n",
    "ivtable.loc[ivtable['variable']=='famsize','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famsizegp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['inctp'].value_counts(sort=False))\n",
    "print(new_data['inctp'].value_counts(normalize=True,sort=False))\n",
    "new_data.loc[new_data['inctp']=='Pensioner','inctp']='State servant'\n",
    "new_data.loc[new_data['inctp']=='Student','inctp']='State servant'\n",
    "iv, data=calc_iv(new_data,'inctp','target')\n",
    "ivtable.loc[ivtable['variable']=='inctp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'inctp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[(new_data['occyp']=='Cleaning staff') | (new_data['occyp']=='Cooking staff') | (new_data['occyp']=='Drivers') | (new_data['occyp']=='Laborers') | (new_data['occyp']=='Low-skill Laborers') | (new_data['occyp']=='Security staff') | (new_data['occyp']=='Waiters/barmen staff'),'occyp']='Laborwk'\n",
    "new_data.loc[(new_data['occyp']=='Accountants') | (new_data['occyp']=='Core staff') | (new_data['occyp']=='HR staff') | (new_data['occyp']=='Medicine staff') | (new_data['occyp']=='Private service staff') | (new_data['occyp']=='Realty agents') | (new_data['occyp']=='Sales staff') | (new_data['occyp']=='Secretaries'),'occyp']='officewk'\n",
    "new_data.loc[(new_data['occyp']=='Managers') | (new_data['occyp']=='High skill tech staff') | (new_data['occyp']=='IT staff'),'occyp']='hightecwk'\n",
    "print(new_data['occyp'].value_counts())\n",
    "iv, data=calc_iv(new_data,'occyp','target')\n",
    "ivtable.loc[ivtable['variable']=='occyp','IV']=iv\n",
    "data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'occyp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'houtp','target')\n",
    "ivtable.loc[ivtable['variable']=='houtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'houtp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['edutp']=='Academic degree','edutp']='Higher education'\n",
    "iv, data=calc_iv(new_data,'edutp','target')\n",
    "ivtable.loc[ivtable['variable']=='edutp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'edutp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Marriage Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data['famtp'].value_counts(normalize=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'famtp','target')\n",
    "ivtable.loc[ivtable['variable']=='famtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famtp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV、WOE：Concept and Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight of Evidence(WoE):  \n",
    "\n",
    "$$wo{e_i} = \\ln {{{P_{yi}}} \\over {{P_{ni}}}} = \\ln {{{y_i}/{y_s}} \\over {{n_i}/{n_s}}}$$\n",
    "$wo{e_i}$ is the I category's WOE value. ${{P_{yi}}}$ is the proportion of the positive samples in this category to all positive samples.   ${{P_{ni}}}$ is the ratio of negative samples (${{n_i}}$) in this class to all negative samples (${{n_s}}$).\n",
    "\n",
    "Information Value (IV):  \n",
    "$$I{V_i} = ({P_{yi}} - {P_{ni}}) \\times wo{e_i}$$  \n",
    "The IV values of the various types are the difference between the conditional positive rate and the conditional negative rate multiplied by the WOE value of the variable. The total IV value of the variable can be understood as the weighted sum of the conditional positive rate and the conditional negative rate difference:\n",
    "$$IV = \\sum\\limits_i^n {I{V_i}} $$  \n",
    "\n",
    "The IV value measures the variable's ability to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between IV value and predictive power\n",
    "\n",
    "| IV| Ability to predict | \n",
    "|:------|:------:| \n",
    "| <0.02 | Almost no predictive power | \n",
    "|0.02~0.1 |weak predictive power|\n",
    "|0.1~0.3|Moderate predictive power|\n",
    "|0.3~0.5|Strong predictive power|\n",
    "|>0.5|Predictive power is too strong, need to check variables| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=ivtable.sort_values(by='IV',ascending=False)\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','variable']='agegp'\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','variable']='worktmgp'\n",
    "ivtable.loc[ivtable['variable']=='inc','variable']='incgp'\n",
    "ivtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_data['target']\n",
    "X = new_data[['Gender','Reality','ChldNo_1', 'ChldNo_2More','wkphone',\n",
    "              'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n",
    "       'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n",
    "       'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n",
    "              'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n",
    "       'houtp_Co-op apartment', 'houtp_Municipal apartment',\n",
    "       'houtp_Office apartment', 'houtp_Rented apartment',\n",
    "       'houtp_With parents','edutp_Higher education',\n",
    "       'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n",
    "       'famtp_Separated','famtp_Single / not married','famtp_Widow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using Synthetic Minority Over-Sampling Technique(`SMOTE`) to overcome sample imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int')\n",
    "X_balance,Y_balance = SMOTE().fit_sample(X,Y)\n",
    "X_balance = pd.DataFrame(X_balance, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ After over sampling, the number between 1 and 0 is balanced. It can be seen from the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balance,Y_balance, \n",
    "                                                    stratify=Y_balance, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression   \n",
    "\n",
    "$$\\log ({p \\over {1 - p}}) = {\\beta _0} + {\\beta _1}{x_1} +  \\cdot  \\cdot  \\cdot  + {\\beta _q}{x_q}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Logistic Regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=12,\n",
    "                               min_samples_split=8,\n",
    "                               random_state=1024)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: CART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest   \n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://d1rwhvwstyk9gu.cloudfront.net/2019/03/Random-Forest-Algorithm.jpg\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Random Forest</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=250,\n",
    "                              max_depth=12,\n",
    "                              min_samples_leaf=16\n",
    "                              )\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Ramdom Forests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://i.loli.net/2019/11/13/fryWG5al7OPHDiA.gif\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Support Vector Machine</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(C = 0.8,\n",
    "                kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(num_leaves=31,\n",
    "                       max_depth=8, \n",
    "                       learning_rate=0.02,\n",
    "                       n_estimators=250,\n",
    "                       subsample = 0.8,\n",
    "                       colsample_bytree =0.8\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(classifer, x_train, point_size = 25):\n",
    "    '''plot feature importance'''\n",
    "    values = sorted(zip(x_train.columns, classifer.feature_importances_), key = lambda x: x[1] * -1)\n",
    "    imp = pd.DataFrame(values,columns = [\"Name\", \"Score\"])\n",
    "    imp.sort_values(by = 'Score',inplace = True)\n",
    "    sns.scatterplot(x = 'Score',y='Name', linewidth = 0,\n",
    "                data = imp,s = point_size, color='red').set(\n",
    "    xlabel='importance', \n",
    "    ylabel='features')\n",
    "    \n",
    "plot_importance(model, X_train,20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=12,\n",
    "                      n_estimators=250,\n",
    "                      min_child_weight=8, \n",
    "                      subsample=0.8, \n",
    "                      learning_rate =0.02,    \n",
    "                      seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model, X_train, 20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.2,\n",
    "                           od_type='Iter',\n",
    "                           verbose=25,\n",
    "                           depth=16,\n",
    "                           random_seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('CatBoost Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 > Please upvote it if you like it! </font>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 426827,
     "sourceId": 1031720,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29840,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
